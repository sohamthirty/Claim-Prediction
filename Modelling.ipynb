{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425fc369",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e7fb61",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e0588b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b50cbf",
   "metadata": {},
   "source": [
    "## Import the sampled csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424b8833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og= pd.read_csv('Data/data_og.csv')  \n",
    "df_nm1= pd.read_csv('Data/data_nm1.csv')  \n",
    "df_nm2= pd.read_csv('Data/data_nm2.csv')  \n",
    "df_nm3= pd.read_csv('Data/data_nm3.csv')  \n",
    "df_rus= pd.read_csv('Data/data_rus.csv')  \n",
    "df_ros= pd.read_csv('Data/data_ros.csv')  \n",
    "df_smote= pd.read_csv('Data/data_smote.csv')  \n",
    "df_smoteen= pd.read_csv('Data/data_smoteen.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0417b25a",
   "metadata": {},
   "source": [
    "## Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d79f6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modellr(df_t,m):\n",
    "    X = df_t.iloc[:, :-1]\n",
    "    y = df_t.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "    #Feature Scaling\n",
    "    sc = StandardScaler()\n",
    "    X_train.loc[:,:] = sc.fit_transform(X_train.loc[:,:])\n",
    "    X_test.loc[:,:] = sc.transform(X_test.loc[:,:])\n",
    "\n",
    "    #Training the model\n",
    "    classifier = LogisticRegression(random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    #Predict\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    #Metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp.append([m,str(round(accuracy_score(y_test, y_pred)*100,2)) + \"%\",str(round(precision_score(y_test, y_pred,zero_division=0),2)),(str(round(recall_score(y_test, y_pred),2))),(str(round(f1_score(y_test, y_pred),2)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71522c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into the Training set and Test set\n",
    "#data_sample_set = ['df_og','df_nm1','df_nm2','df_nm3','df_rus','df_ros','df_smote','df_smoteen']\n",
    "data_sample_set = [df_og,df_nm1,df_nm2,df_nm3,df_rus,df_ros,df_smote,df_smoteen]\n",
    "names = ['Original','Near Miss1', 'Near Miss2','Near Miss3','Random UnderSampling','Random Sampling','Smote','Smoteen' ]\n",
    "\n",
    "allmodels = []\n",
    "\n",
    "disp = []\n",
    "\n",
    "for i in range(0,8):\n",
    "    modellr(data_sample_set[i],names[i])\n",
    "    \n",
    "allmodels.append([\"Logistic Regression\",disp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f92438f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used : Logistic Regression\n",
      "\n",
      "Sampling Technique    Accuracy      Precision    Recall    F1 Score\n",
      "--------------------  ----------  -----------  --------  ----------\n",
      "Original              98.69%             0         0           0\n",
      "Near Miss1            67.24%             0.7       0.62        0.66\n",
      "Near Miss2            79.31%             0.87      0.7         0.77\n",
      "Near Miss3            62.07%             0.62      0.64        0.63\n",
      "Random UnderSampling  71.98%             0.75      0.67        0.71\n",
      "Random Sampling       76.15%             0.78      0.73        0.75\n",
      "Smote                 88.06%             0.84      0.93        0.89\n",
      "Smoteen               90.56%             0.89      0.94        0.91\n"
     ]
    }
   ],
   "source": [
    "print(\"Model used : Logistic Regression\\n\")\n",
    "print(tabulate(disp, headers=[\"Sampling Technique\", \"Accuracy\", \"Precision\",\"Recall\",\"F1 Score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97618fc7",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "725807a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelknn(df_t,m):\n",
    "    X = df_t.iloc[:, :-1]\n",
    "    y = df_t.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "    #Feature Scaling\n",
    "    sc = StandardScaler()\n",
    "    X_train.loc[:,:] = sc.fit_transform(X_train.loc[:,:])\n",
    "    X_test.loc[:,:] = sc.transform(X_test.loc[:,:])\n",
    "\n",
    "    #Training the model\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    #Predict\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    #Metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    disp.append([m,str(round(accuracy_score(y_test, y_pred)*100,2)) + \"%\",str(round(precision_score(y_test, y_pred,zero_division=0),2)),(str(round(recall_score(y_test, y_pred),2))),(str(round(f1_score(y_test, y_pred),2)))])\n",
    "    \n",
    "#Splitting the dataset into the Training set and Test set\n",
    "#data_sample_set = ['df_og','df_nm1','df_nm2','df_nm3','df_rus','df_ros','df_smote','df_smoteen']\n",
    "data_sample_set = [df_og,df_nm1,df_nm2,df_nm3,df_rus,df_ros,df_smote,df_smoteen]\n",
    "names = ['Original','Near Miss1', 'Near Miss2','Near Miss3','Random UnderSampling','Random Sampling','Smote','Smoteen' ]\n",
    "\n",
    "disp = []\n",
    "\n",
    "for i in range(0,8):\n",
    "    modelknn(data_sample_set[i],names[i])\n",
    "    \n",
    "allmodels.append([\"KNN\",disp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d20ccd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used : KNN\n",
      "\n",
      "Sampling Technique    Accuracy      Precision    Recall    F1 Score\n",
      "--------------------  ----------  -----------  --------  ----------\n",
      "Original              98.64%             0         0           0\n",
      "Near Miss1            76.72%             0.84      0.67        0.75\n",
      "Near Miss2            92.24%             0.99      0.86        0.92\n",
      "Near Miss3            65.3%              0.69      0.57        0.63\n",
      "Random UnderSampling  70.26%             0.71      0.7         0.71\n",
      "Random Sampling       97.25%             0.95      1           0.97\n",
      "Smote                 94.94%             0.92      0.98        0.95\n",
      "Smoteen               97.31%             0.96      0.99        0.98\n"
     ]
    }
   ],
   "source": [
    "print(\"Model used : KNN\\n\")\n",
    "print(tabulate(disp, headers=[\"Sampling Technique\", \"Accuracy\", \"Precision\",\"Recall\",\"F1 Score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb814088",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd3a25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeldt(df_t,m):\n",
    "    X = df_t.iloc[:, :-1]\n",
    "    y = df_t.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "    #Feature Scaling\n",
    "    sc = StandardScaler()\n",
    "    X_train.loc[:,:] = sc.fit_transform(X_train.loc[:,:])\n",
    "    X_test.loc[:,:] = sc.transform(X_test.loc[:,:])\n",
    "\n",
    "    #Training the model\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train,y_train)\n",
    "\n",
    "    #Predict\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    #Metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    disp.append([m,str(round(accuracy_score(y_test, y_pred)*100,2)) + \"%\",str(round(precision_score(y_test, y_pred,zero_division=0),2)),(str(round(recall_score(y_test, y_pred),2))),(str(round(f1_score(y_test, y_pred),2)))])\n",
    "    \n",
    "#Splitting the dataset into the Training set and Test set\n",
    "#data_sample_set = ['df_og','df_nm1','df_nm2','df_nm3','df_rus','df_ros','df_smote','df_smoteen']\n",
    "data_sample_set = [df_og,df_nm1,df_nm2,df_nm3,df_rus,df_ros,df_smote,df_smoteen]\n",
    "names = ['Original','Near Miss1', 'Near Miss2','Near Miss3','Random UnderSampling','Random Sampling','Smote','Smoteen' ]\n",
    "\n",
    "disp = []\n",
    "\n",
    "for i in range(0,8):\n",
    "    modeldt(data_sample_set[i],names[i])\n",
    "    \n",
    "allmodels.append([\"Decision Tree\",disp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c205970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used : Decision Tree\n",
      "\n",
      "Sampling Technique    Accuracy      Precision    Recall    F1 Score\n",
      "--------------------  ----------  -----------  --------  ----------\n",
      "Original              97.3%              0.06      0.07        0.06\n",
      "Near Miss1            79.31%             0.8       0.79        0.79\n",
      "Near Miss2            93.53%             0.94      0.94        0.94\n",
      "Near Miss3            62.28%             0.64      0.59        0.61\n",
      "Random UnderSampling  62.72%             0.63      0.63        0.63\n",
      "Random Sampling       98.91%             0.98      1           0.99\n",
      "Smote                 96.89%             0.96      0.98        0.97\n",
      "Smoteen               98.48%             0.98      0.99        0.99\n"
     ]
    }
   ],
   "source": [
    "print(\"Model used : Decision Tree\\n\")\n",
    "print(tabulate(disp, headers=[\"Sampling Technique\", \"Accuracy\", \"Precision\",\"Recall\",\"F1 Score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4839eb",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelNB(df_t,m):\n",
    "    X = df_t.iloc[:, :-1]\n",
    "    y = df_t.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "    #Feature Scaling\n",
    "    sc = StandardScaler()\n",
    "    X_train.loc[:,:] = sc.fit_transform(X_train.loc[:,:])\n",
    "    X_test.loc[:,:] = sc.transform(X_test.loc[:,:])\n",
    "\n",
    "    #Training the model\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train,y_train)\n",
    "\n",
    "    #Predict\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    #Metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    disp.append([m,str(round(accuracy_score(y_test, y_pred)*100,2)) + \"%\",str(round(precision_score(y_test, y_pred,zero_division=0),2)),(str(round(recall_score(y_test, y_pred),2))),(str(round(f1_score(y_test, y_pred),2)))])\n",
    "    \n",
    "#Splitting the dataset into the Training set and Test set\n",
    "#data_sample_set = ['df_og','df_nm1','df_nm2','df_nm3','df_rus','df_ros','df_smote','df_smoteen']\n",
    "data_sample_set = [df_og,df_nm1,df_nm2,df_nm3,df_rus,df_ros,df_smote,df_smoteen]\n",
    "names = ['Original','Near Miss1', 'Near Miss2','Near Miss3','Random UnderSampling','Random Sampling','Smote','Smoteen' ]\n",
    "\n",
    "disp = []\n",
    "\n",
    "for i in range(0,8):\n",
    "    modelNB(data_sample_set[i],names[i])\n",
    "    \n",
    "allmodels.append([\"Naive Bayes\",disp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fafaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model used : Naive Bayes\\n\")\n",
    "print(tabulate(disp, headers=[\"Sampling Technique\", \"Accuracy\", \"Precision\",\"Recall\",\"F1 Score\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
